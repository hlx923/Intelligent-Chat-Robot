import ollama
from langdetect import detect
import re
import emoji
from transformers import pipeline
import logging
from typing import Dict, Optional, Any

class OllamaModelManager:
    def __init__(self):
        self.client = ollama.Client()
        self.models = {
            'qwen2': {
                'name': 'qwen2',
                'temperature': 0.7,
                'top_p': 0.9,
                'context_length': 2048
            },
            'deepseek-r1': {
                'name': 'deepseek-r1',
                'temperature': 0.8,
                'top_p': 0.9,
                'context_length': 4096
            }
        }
        self.default_model = 'qwen2'
        self._initialize_models()

    def _check_ollama_service(self):
        import socket
        try:
            # æ£€æŸ¥Ollamaé»˜è®¤ç«¯å£(11434)æ˜¯å¦å¯è®¿é—®
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            result = sock.connect_ex(('127.0.0.1', 11434))
            sock.close()
            print(f"OllamaæœåŠ¡ç«¯å£æ£€æŸ¥ç»“æžœ: {result == 0}")
            return result == 0
        except Exception as e:
            print(f"æ£€æŸ¥OllamaæœåŠ¡æ—¶å‡ºé”™: {e}")
            return False

    def _initialize_models(self):
        try:
            # print("æ­£åœ¨æ£€æŸ¥OllamaæœåŠ¡...")
            # èŽ·å–å¯ç”¨æ¨¡åž‹åˆ—è¡¨
            available_models = self.client.list()
            # print(f"Ollamaè¿”å›žæ•°æ®: {available_models}")
            
            # é€‚é…æ–°çš„APIè¿”å›žç±»åž‹
            model_names = []
            if hasattr(available_models, 'models'):
                # æ–°ç‰ˆAPIè¿”å›žListResponseå¯¹è±¡
                model_names = [model.model.split(':')[0] for model in available_models.models]
            
            # print(f"å·²å®‰è£…çš„æ¨¡åž‹: {model_names}")
            
            # æ£€æŸ¥æ‰€éœ€æ¨¡åž‹æ˜¯å¦éƒ½å·²å®‰è£…ï¼Œå…è®¸æ¨¡åž‹åç§°å‰ç¼€åŒ¹é…
            missing_models = []
            for model in self.models.keys():
                # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„æ¨¡åž‹åç§°ï¼ˆå…è®¸å‰ç¼€åŒ¹é…ï¼Œå¦‚deepseek-r1åŒ¹é…deepseekï¼‰
                if not any(installed.startswith(model) or model.startswith(installed) for installed in model_names):
                    missing_models.append(model)
            
            # æ›´æ–°æ¨¡åž‹åç§°ä¸ºå®žé™…å®‰è£…çš„åç§°
            for model_key in list(self.models.keys()):
                for installed in model_names:
                    if installed.startswith(model_key) and installed != model_key:
                        # æ‰¾åˆ°åŒ¹é…çš„æ¨¡åž‹ï¼Œæ›´æ–°é…ç½®
                        print(f"å°†ä½¿ç”¨ {installed} æ›¿ä»£ {model_key}")
                        config = self.models[model_key].copy()
                        config['name'] = installed
                        self.models[model_key] = config
            
            if missing_models:
                print("\néœ€è¦å®‰è£…ä»¥ä¸‹æ¨¡åž‹:")
                for model in missing_models:
                    print(f"- {model}: è¯·æ‰§è¡Œå‘½ä»¤ 'ollama pull {model}'")
                print("\nè¯·å®‰è£…å®Œæ‰€éœ€æ¨¡åž‹åŽé‡æ–°å¯åŠ¨åº”ç”¨ã€‚\n")
                return False
            
            # print("âœ“ OllamaæœåŠ¡è¿žæŽ¥æˆåŠŸ")
            # print("âœ“ æ‰€éœ€æ¨¡åž‹å·²å…¨éƒ¨å®‰è£…\n")
            return True
        except Exception as e:
            print(f"âŒ è¿žæŽ¥OllamaæœåŠ¡å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿OllamaæœåŠ¡å·²å¯åŠ¨ï¼Œå¹¶ä¸”å·²å®‰è£…æ‰€éœ€æ¨¡åž‹")
            return False

    def generate_response(self, prompt: str, model_name: str, **kwargs) -> str:
        from error_handler import ErrorHandler, RetryStrategy
        
        @ErrorHandler.with_retry(RetryStrategy(max_retries=3, delay=1.0, backoff=2.0))
        def _generate(self, prompt: str, model_name: str) -> str:
            model_config = self.models.get(model_name, self.models[self.default_model])
            result = self.client.generate(model_name, prompt)
            return result['response']
        
        return _generate(self, prompt, model_name)

class LanguageProcessor:
    @staticmethod
    def detect_language(text: str) -> str:
        try:
            return detect(text)
        except:
            return 'en'

    @staticmethod
    def select_model(prompt: str) -> str:
        if re.search(r'\b(ä¸“ä¸š|æŠ€æœ¯|å­¦æœ¯|ä»£ç |ç¼–ç¨‹)\b', prompt):
            return 'deepseek'
        return 'qwen2'

class EmotionAnalyzer:
    def __init__(self):
        self.analyzer = self._initialize_analyzer()
        self.responses = {
            'joy': "å¤ªæ£’å•¦ðŸŽ‰ å¸Œæœ›æ‚¨ä¸€ç›´ä¿æŒè¿™ä»½å¥½å¿ƒæƒ…ï¼",
            'sadness': "åˆ«éš¾è¿‡ðŸ˜¢ æˆ‘ä¼šä¸€ç›´é™ªç€æ‚¨çš„ã€‚",
            'anger': "æ¶ˆæ¶ˆæ°”ðŸ¥º æœ‰ä»€ä¹ˆé—®é¢˜æˆ‘ä»¬æ…¢æ…¢è§£å†³ã€‚",
            'fear': "åˆ«æ€•åˆ«æ€•ðŸ™Œ æˆ‘ä¼šä¿æŠ¤æ‚¨çš„ã€‚",
            'neutral': "äº†è§£å•¦ï¼Œè¯·æ‚¨ç»§ç»­è¯´ã€‚"
        }

    def _initialize_analyzer(self):
        try:
            from transformers import logging as transformers_logging
            transformers_logging.set_verbosity_error()
            return pipeline("text-classification", model="j-hartmann/emotion-english-distilroberta-base")
        except Exception as e:
            logging.warning(f"æ— æ³•åŠ è½½æƒ…æ„Ÿåˆ†æžæ¨¡åž‹: {e}")
            return None

    def analyze(self, text: str) -> str:
        if not self.analyzer:
            return self._keyword_based_analysis(text)
        
        try:
            result = self.analyzer(text)[0]
            return self.responses.get(result['label'], self.responses['neutral'])
        except Exception as e:
            logging.error(f"æƒ…æ„Ÿåˆ†æžå‡ºé”™: {e}")
            return self.responses['neutral']

    def _keyword_based_analysis(self, text: str) -> str:
        text = text.lower()
        if any(word in text for word in ['å¼€å¿ƒ', 'é«˜å…´', 'æ£’']):
            return self.responses['joy']
        elif any(word in text for word in ['éš¾è¿‡', 'ä¼¤å¿ƒ', 'å“­']):
            return self.responses['sadness']
        elif any(word in text for word in ['ç”Ÿæ°”', 'æ„¤æ€’', 'æ°”æ­»']):
            return self.responses['anger']
        elif any(word in text for word in ['å®³æ€•', 'ææƒ§', 'å“']):
            return self.responses['fear']
        return self.responses['neutral']

# åˆå§‹åŒ–å…¨å±€å®žä¾‹
model_manager = OllamaModelManager()
language_processor = LanguageProcessor()
emotion_analyzer = EmotionAnalyzer()

# ä¿®æ”¹å¯¼å‡ºå‡½æ•°
def generate_response(prompt: str, model: str, **kwargs) -> str:
    # èŽ·å–åŽŸå§‹å“åº”
    response = model_manager.generate_response(prompt, model, **kwargs)
    
    # å¯¼å…¥å¹¶ä½¿ç”¨å“åº”å¤„ç†å™¨æ¸…ç†è¾“å‡º
    from response_processor import clean_response
    return clean_response(response)

def select_model(prompt: str) -> str:
    return language_processor.select_model(prompt)

def detect_language(text: str) -> str:
    return language_processor.detect_language(text)

def emotional_response(prompt: str) -> str:
    return emotion_analyzer.analyze(prompt)